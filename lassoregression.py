# -*- coding: utf-8 -*-
"""LassoRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uDymfo-milrMmMO07-gBynNUcT_jFUyM
"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import division
import sys
import numpy as np
import time
import scipy.io as io
import scipy.sparse as sparse
import matplotlib.pyplot as plt
# %matplotlib inline

# synthetic data generator
# n is number of samples, d is number of dimensions, k is number of nonzeros in w, sigma is std of noise,
# X is a n x d data matrix, y=Xw+w_0+noise is a n-dimensional vector, w is the true weight vector, w0 is true intercept
def DataGenerator(n = 50, d = 75, k = 5, sigma = 1.0, w0 = 0.0, seed = 256):

    np.random.seed(seed)
    X = np.random.normal(0,1,(n,d))
    w = np.random.binomial(1,0.5,k)
    noise = np.random.normal(0,sigma,n)
    w[w == 1] = 10.0
    w[w == 0] = -10.0
    w = np.append(w, np.zeros(d - k))
    y = X.dot(w) + w0 + noise
    return (X, y, w, w0)

# initialization of W lasso by least square regression or ridge regression
def Initialw(X, y):

    n, d = X.shape
    # increment X
    if sparse.issparse(X):
        XI = sparse.hstack((X, np.ones(n).reshape(n,1)))
    else:
        XI = np.hstack((X, np.ones(n).reshape(n,1)))

    if sparse.issparse(X):
        if n >= d:
            w = sparse.linalg.lsqr(XI, y)[0]
        else:
            w = sparse.linalg.inv(XI.T.dot(XI) + 1e-3 * sparse.eye(d+1)).dot(XI.T.dot(y))
            w = w.T
    else:
        if n >= d:
            w = np.linalg.lstsq(XI, y)[0]
        else:
            w = np.linalg.inv(XI.T.dot(XI) + 1e-3 * np.eye(d+1)).dot(XI.T.dot(y))

    return (w[:d], w[d])

def cscMatInplaceEleMultEveryRow(W, x):
    indptr = W.indptr
    last_idx = indptr[0]
    for col_id, idx in enumerate(indptr[1:]):
        if idx == last_idx:
            continue
        else:
            W.data[last_idx:idx] *= x[col_id]
            last_idx = idx

def lasso(X, y, lmda=10.0, epsilon=1.0e-2, max_iter=100, draw_curve=True):
    n, d = X.shape
    w, w0 = Initialw(X, y)
    obj_val = []
    print(f'Shape of X: {X.shape}')

    for t in range(max_iter):
        w_old = w.copy()
        print(f'Shape of X: {X.shape}')
        print(f'Value of d: {d}')
        for j in range(d):
            # update w[j]
            r_j = y - w0 - X @ w + X[:, j] * w[j]
            rho_j = X[:, j] @ r_j
            print(f'rho_j for j={j} is {rho_j}')

            if rho_j < -lmda/2:
                w[j] = (rho_j + lmda/2) / (X[:, j]**2).sum()
                print(f'Updated w[{j}] in the first condition')
            elif rho_j > lmda/2:
                w[j] = (rho_j - lmda/2) / (X[:, j]**2).sum()
                print(f'Updated w[{j}] in the second condition')
            else:
                w[j] = 0
                print(f'Set w[{j}] to 0')

        w0 = (y - X @ w).mean()
        obj = ((y - w0 - X @ w)**2).sum() / 2 + lmda * np.abs(w).sum()
        obj_val.append(obj)
        if np.max(np.abs(w - w_old)) < epsilon:
            break
    if draw_curve==True:
        plt.plot(range(1, len(obj_val) + 1), obj_val)
        plt.xlabel('Iteration')
        plt.ylabel('Objective value')
        plt.show()
    return w, w0

X, y, w_true, w0_true = DataGenerator(n=50, d=75, k=5, sigma=1.0)
print(X)
print(y)
print(w_true)
print(w0_true)